{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 1 IMPORT LIBRARY FUNCTIONS\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.preprocessing.image import load_img\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.python.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2 \n",
    "#I have created a folder with 112 images of mine\n",
    "# in this step i will read all the images from the folder\n",
    "#and convert all the images into array using img_to_array functions\n",
    "filename  =  \"C:/Users/amukhopa/Desktop/KAGGLE/AVISHEK/PICFOLDER/Avishek\"\n",
    "imagearray = []\n",
    "for name in listdir(filename):\n",
    "    picname = filename + '/' + name\n",
    "    image = load_img(picname, target_size=(224,224))\n",
    "    image = img_to_array(image)\n",
    "    imagearray.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 3\n",
    "#checking the shape of image array\n",
    "# the image array will be 4 dimensional, first dimension is number of pics \n",
    "#other dimensions will be image dimension\n",
    "imagearray = np.array(imagearray)\n",
    "imagearray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING THE MODEL  - Conv 2D is deliberately not used \n",
    "model = Sequential()\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amukhopa\\Documents\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "layer_1 = Dense(8, input_shape = (150528,), activation = 'relu')\n",
    "model.add(layer_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_2 = Dense(4, activation = 'relu')\n",
    "model.add(layer_2)\n",
    "layer_3 = Dense(1, activation = 'sigmoid')\n",
    "model.add(layer_3)\n",
    "model.compile(loss='huber_loss',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTING ALL Y EQUAL TO 1 for COMPILING\n",
    "y = np.arange(112)\n",
    "for i in range(112):\n",
    "    y[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amukhopa\\Documents\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.5000 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.5000 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.5000 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.5000 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.5000 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.5000 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.5000 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.5000 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.5000 - acc: 0.0000e+00 0s - loss: 0.5000 - acc: 0.000\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.5000 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x222dda5cd88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(imagearray, y, epochs=10, batch_size=3)mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOADING A TEST IMAGE IN JUPYTER AND CONVERTING IT INTO 32 BY 32 MATRIX\n",
    "testfile = \"C:/Users/amukhopa/Desktop/KAGGLE/AVISHEK/avishektest/620.jpg\"\n",
    "testimage = load_img(testfile, target_size=(224,224))\n",
    "image_test= np.array(testimage)\n",
    "image_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = image_test.reshape(1, image_test.shape[0], image_test.shape[1], image_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1204232   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  36        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  5         \n",
      "=================================================================\n",
      "Total params: 1,204,273\n",
      "Trainable params: 1,204,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
